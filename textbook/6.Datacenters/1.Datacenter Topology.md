# 数据中心拓扑结构

## 什么是数据中心？

到目前为止，在我们的互联网模型中，我们展示了终端主机之间相互发送数据包的场景。终端主机可能是客户端机器（例如你的本地计算机），也可能是服务器（例如 YouTube 服务器）。但是，YouTube 真的是互联网上一台单独的机器，向全世界提供视频服务吗？



![img](https://textbook.cs168.io/assets/datacenter/6-001-single-server.png)

实际上，YouTube 是一整栋楼里互联的机器，它们协同工作，向客户端提供视频服务。所有这些机器都处于同一个本地网络中，能够相互通信以完成请求（例如，如果你请求的视频存储在不同的机器上）。



![img](https://textbook.cs168.io/assets/datacenter/6-002-many-servers.png)

回想一下互联网的 “网络的网络” 模型，每个运营商都可以自由管理自己的本地网络。在本节中，我们将重点关注专门用于连接数据中心内部服务器的本地网络（与像你的个人计算机这样的用户设备相对）。我们将讨论这些本地网络特有的挑战，以及专门为数据中心环境设计的网络问题（如拥塞控制和路由）的解决方案。

在现实生活中，数据中心位于一个物理位置，通常在专用场地。除了计算基础设施（如服务器），数据中心还需要冷却系统和电源等支持性基础设施，不过我们将重点关注连接服务器的本地网络。

数据中心为各种应用提供服务（如 YouTube 视频、谷歌搜索结果等）。这是你可能想要连接的终端主机的基础设施。请注意，这与我们到目前为止看到的互联网基础设施不同。之前，我们了解过运营商酒店，即许多网络（由不同公司拥有）通过高性能路由器相互连接的建筑。这是路由器将你的数据包转发到各个目的地的基础设施，但应用程序通常不会托管在运营商酒店中。

一个数据中心通常由单个组织（如谷歌、亚马逊）拥有，该组织可以在一个数据中心中托管许多不同的应用程序（如 Gmail、YouTube 等）。这意味着该组织可以控制数据中心本地网络内的所有网络基础设施。

我们的重点是现代超大规模数据中心，由谷歌和亚马逊等科技巨头运营。大规模带来了一些独特的挑战，但我们将看到的概念在较小规模下也同样适用。



![img](https://textbook.cs168.io/assets/datacenter/6-003-wan1.png)

这张地图显示了像谷歌这样的科技巨头所拥有的所有网络组成的广域网（WAN）。

对等点位置将谷歌与互联网的其他部分连接起来。这些位置主要由谷歌运营的路由器组成，这些路由器连接到其他自治系统。



![img](https://textbook.cs168.io/assets/datacenter/6-004-peering.png)

除了对等点位置，谷歌还运营着许多数据中心。数据中心中的应用程序可以通过对等点位置与互联网的其他部分通信。数据中心和对等点位置都通过谷歌广域网中由谷歌管理的路由器和链路连接起来。



![img](https://textbook.cs168.io/assets/datacenter/6-005-datacenter-irl1.png)

数据中心和对等点位置优化的性能目标不同，因此它们通常位于不同的物理位置。

对等点位置注重物理上靠近其他公司和网络。因此，运营商酒店通常位于城市中，以便在物理上更接近客户和其他公司。

相比之下，数据中心不太在意是否靠近其他公司，而是更看重物理空间、电力和冷却等要求。因此，数据中心通常位于人口较少的地区，有时靠近河流（用于冷却）或发电站（数据中心的电力需求可能是对等点位置的数百倍）。



![img](https://textbook.cs168.io/assets/datacenter/6-006-datacenter-irl2.png)

## 数据中心有何不同之处？

数据中心的本地网络与互联网上的通用（广域）网络有何不同？

数据中心网络由单个组织运营，这使我们对网络和主机有更多的控制权。与通用互联网不同，我们可以运行自己的定制硬件或软件，并且可以强制每台机器遵循相同的定制协议。

数据中心通常是同构的，即每台服务器和交换机的构建和运营方式完全相同。与通用互联网不同，我们不必考虑有些链路是无线的，而有些是有线的。在通用互联网中，有些计算机可能比其他计算机更新，但在数据中心中，每台计算机通常属于同一代，并且整个数据中心会同时升级。

数据中心网络位于单个物理位置，因此我们不必考虑像海底电缆这样的长距离链路。在这个单一位置内，我们需要支持极高的带宽。

## 数据中心流量模式

当你向数据中心应用程序发出请求时，你的数据包会通过通用互联网中的路由器传输，最终到达谷歌运营的路由器。该路由器将你的数据包转发到数据中心的一个边缘路由器，边缘路由器再将数据包转发到数据中心内的某个服务器。

这台服务器可能没有处理你的请求所需的所有信息。例如，如果你请求了 Facebook 动态，不同的服务器可能需要协同工作，才能整合广告、照片、帖子等内容。如果每台服务器都必须了解 Facebook 的所有信息才能单独处理你的请求，那是不现实的。

为了让不同的服务器协同工作，第一台服务器会触发许多后端请求，以收集处理你的请求所需的所有信息。一个用户请求可能需要触发数百个后端请求（根据 2013 年 Facebook 的一篇论文，平均为 521 个），然后才能将响应发送回用户。一般来说，服务器之间的后端流量要多得多，而与用户的外部流量相比则非常少。



![img](https://textbook.cs168.io/assets/datacenter/6-007-nsew-traffic1.png)

大多数现代应用程序以机器之间的内部流量为主。例如，如果你运行像 MapReduce 这样的分布式程序，不同的服务器需要相互通信才能共同解决你的大型查询。有些应用程序甚至可能完全没有面向用户的网络流量。例如，谷歌可能会运行定期备份，这需要服务器之间进行通信，但不会给最终用户带来可见的结果。

走出网络的连接（例如到终端用户或其他数据中心）被称为**南北向流量**。相比之下，网络内部机器之间的连接被称为**东西向流量**。东西向流量比南北向流量大几个数量级，并且近年来东西向流量的规模还在不断增长（例如，随着机器学习的发展）。



![img](https://textbook.cs168.io/assets/datacenter/6-008-nsew-traffic2.png)

## 机架

数据中心本质上由许多服务器组成。服务器按物理机架组织，每个机架有 40-48 个机架单元（插槽），每个机架单元可以容纳 1-2 台服务器。



![img](https://textbook.cs168.io/assets/datacenter/6-009-rack1.png)

我们希望数据中心内的所有服务器都能相互通信，因此我们需要构建一个网络来连接它们所有。这个网络会是什么样子？我们如何有效地安装链路和交换机以满足我们的需求？

首先，我们可以连接单个机架内的所有服务器。每个机架都有一个称为**机架顶部（TOR）交换机**的交换机，机架中的每台服务器都有一条链路（称为**接入链路**或**上行链路**）连接到该交换机。TOR 是一个相对较小的路由器，有一个转发芯片和连接到机架上所有服务器的物理端口。每个服务器上行链路的容量通常约为 100 Gbps。



![img](https://textbook.cs168.io/assets/datacenter/6-010-rack2.png)

接下来，我们必须考虑如何将机架连接起来。理想情况下，我们希望每台服务器都能以其全速（即使用整个上行链路带宽）与其他每台服务器通信。



![img](https://textbook.cs168.io/assets/datacenter/6-011-rack3.png)

## 二分带宽

在考虑如何连接机架之前，让我们先制定一个衡量一组计算机连接程度的指标。



![img](https://textbook.cs168.io/assets/datacenter/6-012-bisection1.png)

直观地说，尽管这三个网络都是完全连接的，但左边的网络连接最紧密，中间的次之，右边的最不紧密。例如，左边和中间的网络可以支持 1-4 和 3-6 同时以全速通信，而右边的网络则不能。

认为左边的网络连接更紧密的一种理由是：我们需要切断更多的链路才能断开网络。这表明存在许多冗余链路，这使我们能够运行许多同时进行的高带宽连接。同样，认为右边的网络连接不太紧密的一种理由是：我们只需要切断 2-5 链路就能断开网络，这表明存在瓶颈，阻碍了同时进行的高带宽连接。

**二分带宽**是一种量化网络连接程度的方法。为了计算二分带宽，我们计算将网络分成两个大小相等的断开部分所需移除的链路数量。二分带宽是我们所切断的链路上的带宽总和。



![img](https://textbook.cs168.io/assets/datacenter/6-013-bisection2.png)

在最右边的结构中，我们只需要移除一条链路就能分割网络，因此二分带宽就是这条链路的带宽。相比之下，在最左边的结构中，我们需要移除 9 条链路才能分割网络，因此二分带宽是所有 9 条链路的总带宽。

二分带宽的另一种等效定义是：我们将网络分成两部分，一部分中的每个节点都想同时向另一部分中的对应节点发送数据。在所有可能的节点分区中，节点总共能发送的最小带宽是多少？考虑最坏情况（最小带宽）迫使我们思考瓶颈问题。



![img](https://textbook.cs168.io/assets/datacenter/6-014-bisection3.png)

连接最紧密的网络具有完整的二分带宽。这意味着没有瓶颈，无论你如何将节点分配到不同分区，一个分区中的所有节点都能以全速与另一个分区中的所有节点同时通信。如果有 N 个节点，左分区中的所有 N/2 个节点都以全速 R 发送数据，那么完整的二分带宽就是 N/2 乘以 R。

**超额订阅**是衡量我们离完整二分带宽有多远的指标，或者说，网络瓶颈部分的过载程度。它是二分带宽与完整二分带宽（所有主机以全速发送时的带宽）的比率。



![img](https://textbook.cs168.io/assets/datacenter/6-015-bisection4.png)

在最右边的例子中，假设所有链路都是 1 Gbps，那么二分带宽是 2 Gbps（将左边四个主机与右边四个主机分开）。当左边四个主机同时发送数据时，完整的二分带宽是 4 Gbps。因此，比率 2/4 告诉我们，主机只能以其全速的 50% 发送数据。换句话说，我们的网络是 2 倍超额订阅的，因为如果所有主机都以全速发送，瓶颈链路将过载 2 倍（2 Gbps 的链路上有 4 Gbps 的流量）。

## 数据中心拓扑结构

现在我们已经定义了二分带宽，这是一种取决于网络拓扑结构的连接程度度量。在数据中心中，我们可以选择我们的拓扑结构（例如选择在哪里安装电缆）。我们应该构建什么样的拓扑结构来最大化二分带宽？

一种可能的方法是将每个机架连接到一个巨大的交叉开关。左边的所有机架可以同时以全速将数据发送到交换机，交换机再以全速将所有数据转发到右边。这将使我们能够实现完整的二分带宽。



![img](https://textbook.cs168.io/assets/datacenter/6-016-topology1.png)

这种方法有什么问题？交换机需要为每个机架配备一个物理端口（可能多达 2500 个端口）。我们有时将外部端口的数量称为交换机的**端口数**，因此这种交换机需要很大的端口数。此外，这种交换机需要巨大的容量（可能达到每秒拍字节）来支持所有机架。不出所料，这种交换机在实际中难以构建（即使我们能够构建，其成本也高得令人望而却步）。

有趣的事实：在 2000 年代，谷歌曾要求交换机供应商制造 10,000 端口的交换机。供应商拒绝了，称这不可能实现，即使能够实现，除了谷歌也没有人会需要（因此制造它没有利润）。

另一个问题是，这种交换机是一个单点故障，如果这个交换机出现故障，整个数据中心网络将停止工作。

另一种可能的方法是将交换机排列成树形拓扑结构。这可以帮助我们减少端口数和每条链路的带宽。



![img](https://textbook.cs168.io/assets/datacenter/6-017-topology2.png)

这种方法有什么问题？二分带宽较低。一条链路是树的两个半部分之间的瓶颈。

为了增加二分带宽，我们可以在更高层安装更高带宽的链路。



![img](https://textbook.cs168.io/assets/datacenter/6-018-topology3.png)

在这种情况下，如果四条较低的链路是 100 Gbps，两条较高的链路是 300 Gbps，那么我们就消除了瓶颈并恢复了完整的二分带宽。

这种拓扑结构是可以使用的，尽管我们仍然没有解决顶部交换机成本高、扩展性差的问题。

## Clos 网络

到目前为止，我们尝试使用定制构建的交换机来构建网络，这些交换机可能具有非常高的带宽或端口数。这些交换机的建造成本仍然很高。我们是否可以设计一种使用廉价通用组件就能实现高二分带宽的拓扑结构？特别是，我们希望使用大量廉价的现成交换机，所有交换机都具有相同数量的端口，每个交换机的端口数量少，并且所有链路速度相同。



![img](https://textbook.cs168.io/assets/datacenter/6-019-clos1.png)

**Clos 网络**通过在网络中的节点之间引入大量路径，使用通用组件实现了高带宽。由于网络中有如此多的链路和路径，我们可以通过让每个节点沿着不同的路径发送数据来实现高二分带宽。



![img](https://textbook.cs168.io/assets/datacenter/6-020-clos2.png)

与定制构建的交换机不同（我们通过制造更大的交换机来扩展网络），我们可以通过简单地添加更多相同的交换机来扩展 Clos 网络。这种解决方案具有成本效益且可扩展！

Clos 网络也被用于其他应用中，其名称来源于其发明者（Charles Clos，1952 年）。

在经典的 Clos 网络中，左边的所有机架将数据发送到右边的机架。在数据中心中，机架既可以发送也可以接收数据，因此我们不需要将发送方和接收方分为不同的层，而是可以用一个包含所有机架的单层（既作为发送方也作为接收方）。然后，数据沿着网络深处的众多路径之一传输，然后再传出以到达接收方。其结果被称为**折叠 Clos 网络**，因为我们将发送方和接收方层 “折叠” 成了一个。



![img](https://textbook.cs168.io/assets/datacenter/6-021-clos3.png)

## 胖树 Clos 拓扑结构

胖树拓扑结构每个交换机的端口数少，并实现了完整的二分带宽。然而，树顶部的交换机成本高、扩展性差，仍然是一个单点故障。

Clos 拓扑结构允许我们使用通用交换机来扩展我们的网络。如果我们将 Clos 拓扑结构与胖树拓扑结构相结合，我们就可以用通用交换机构建一个可扩展的拓扑结构！

这里介绍的拓扑结构来自 2008 年 SIGCOMM 的一篇论文，标题为《A Scalable, Commodity Data Center Network Architecture》（Mohammad Al-Fares、Alexander Loukissas、Amin Vahdat）。

在 k 叉胖树中，我们创建 k 个 pod。每个 pod 有 k 个交换机。

在一个 pod 内，k/2 个交换机位于上层汇聚层，另外 k/2 个交换机位于下层边缘层。

（注意：这种拓扑结构是为偶数 k 定义的，以便我们可以在汇聚层和边缘层之间平均分配交换机）。



![img](https://textbook.cs168.io/assets/datacenter/6-022-pods1.png)

pod 中的每个交换机有 k 条链路。一半的链路（k/2）向上连接，另一半（k/2）向下连接。

考虑上层汇聚层的一个交换机。它的一半链路（k/2）向上连接到核心层（核心层用于连接各个 pod，下文将详细讨论）。另一半链路（k/2）向下连接到边缘层的 k/2 个交换机。

同样，考虑下层边缘层的一个交换机。它的一半链路（k/2）向上连接到同一 pod 中汇聚层的 k/2 个交换机。另一半链路（k/2）向下连接到该 pod 中的 k/2 个主机。



![img](https://textbook.cs168.io/assets/datacenter/6-023-pods2.png)

接下来，让我们看看核心层，它用于连接各个 pod。每个核心交换机有 k 条链路，分别连接到 k 个 pod 中的每个 pod。

核心交换机的数量为 (k/2)²。我们是如何得出这个数字的？有 k 个 pod，每个 pod 的上层汇聚层有 k/2 个交换机，因此汇聚层总共有 k²/2 个交换机。每个汇聚层交换机有 k/2 条向上的链路，因此向上的链路总数为 k²/2×k/2=k³/4。这意味着核心层需要有总共 k³/4 条向下的链路，以匹配汇聚层向上的链路数量。

每个核心层交换机有 k 条向下的链路，因此我们需要 k²/4 个核心层交换机（每个有 k 条链路）来创建 k³/4 条指向下方的链路。这使得汇聚层向上的链路数量与核心层向下的链路数量相匹配。

我们还可以计算出在这种拓扑结构中，每个 pod 有 (k/2)² 个主机。我们是如何得出这个数字的？每个 pod 的边缘层有 k/2 个交换机。每个边缘层交换机有 k/2 条向下的链路连接到主机，因此每个 pod 总共有 k/2×k/2=(k/2)² 个主机。请注意，每个主机只连接到一个边缘层交换机（在这种拓扑结构中，一个主机不会连接到多个交换机）。由于总共有 k 个 pod，我们可以推断出拓扑结构中总共有 (k/2)²×k 个主机。



![img](https://textbook.cs168.io/assets/datacenter/6-024-pods3.png)

最小的例子 k=4 不幸有点令人困惑，因为有些数字巧合地相同（例如，(k/2)²=k=4）。为了更清楚地说明，我们可以看一下 k=6 的例子。

每个 pod 有 k=6 个交换机。k/2=3 个交换机位于上层汇聚层，k/2=3 个交换机位于下层边缘层。

一个边缘层交换机有 k/2=3 条向下的链路连接到 3 个主机，还有 k/2=3 条向上的链路连接到同一 pod 中的 3 个汇聚交换机。

一个汇聚层交换机有 k/2=3 条向上的链路连接到核心层（具体来说，是 3 个不同的核心层交换机），还有 k/2=3 条向下的链路连接到同一 pod 中的 3 个边缘层交换机。

每个 pod 有 k/2=3 个边缘交换机，每个边缘交换机连接到 k/2=3 个主机，因此每个 pod 总共有 (k/2)²=9 个主机。该拓扑结构总共有 k 个 pod，因此总共有 k×(k/2)²=54 个主机。

在核心层，我们有 (k/2)²=9 个核心交换机。每个交换机有 k=6 条链路，向下连接到 k=6 个 pod 中的每个 pod。

核心层总共有 (k/2)²×k 条向下的链路（核心交换机的数量乘以每个交换机的链路数量）。汇聚层有 k×(k/2)×(k/2) 条向上的链路（pod 的数量乘以每个 pod 中的汇聚交换机数量，再乘以每个汇聚交换机的向上链路数量）。这两个表达式是相等的（对于 k=6，结果都是 54），使得核心层能够与汇聚层完全连接。



![img](https://textbook.cs168.io/assets/datacenter/6-025-pods4.png)

这种拓扑结构实现了完整的二分带宽。如果你将 pod 分成两半（例如左半部分和右半部分），那么左半部分的每个主机都有一条专用路径到右半部分的对应主机。这使得所有主机都能配对（一个在左半部分，一个在右半部分），并且每对主机都能沿着专用路径通信，没有瓶颈。

此外，请注意，这种拓扑结构可以用通用交换机构建。无论交换机位于哪一层，每个交换机都有 k 条链路的端口数。而且，每条链路可以具有相同的带宽（例如 1 Gbps），其可扩展性来自于我们在任意一对主机之间创建了专用路径这一事实。



![img](https://textbook.cs168.io/assets/datacenter/6-026-pods5.png)

另一种理解完整二分带宽的方式是：删除链路，直到网络被分成两半（左半部分的 pod 和右半部分的 pod）。

每个核心层交换机有 k 条链路，分别连接到每个 pod。这也意味着每个核心层交换机有 k/2 条链路连接到左侧，k/2 条链路连接到右侧。

为了完全隔离一侧（例如完全隔离左侧），对于每个核心交换机，我们必须切断连接到左侧的 k/2 条链路。有 (k/2)² 个核心交换机，每个交换机需要切断 k/2 条链路，因此总共切断 (k/2)³ 条链路。这意味着我们的二分带宽是 (k/2)³ 条链路（假设每条链路的带宽相同）。

每个 pod 有 (k/2)² 个主机，左侧有 k/2 个 pod，因此左侧总共有 (k/2)³ 条链路。同样，右侧有 (k/2)³ 条链路。如果左侧的每个主机都想与右侧的每个主机通信，那么需要 (k/2)³ 条链路的带宽。我们的二分带宽与这个数字匹配，这意味着实现了完整的二分带宽。



![img](https://textbook.cs168.io/assets/datacenter/6-027-pods6.png)

这种 Clos 胖树拓扑结构与前面提到的机架和机架顶部交换机有什么关系？

对于特定的合适 k 值，我们可以将 pod 内的主机和交换机安排到不同的机架中，并将这些机架相互连接。

例如，考虑原始论文中使用的示例值 k=48。这意味着在一个 pod 内，有 k/2=24 个汇聚层交换机、k/2=24 个边缘层交换机，以及 (k/2)²=576 个主机。

我们可以这样安排交换机和主机：所有 48 个交换机都放在中间的一个机架中。然后，我们可以在这个交换机机架周围放置 12 个机架，每个机架容纳 48 台主机。这有助于我们将所有交换机和主机放入大小相同的机架中（每个机架 48 台机器）。将交换机放在中间的机架中还可以减少构建这种拓扑结构所需的物理布线量。

中间的机架有 k=48 个交换机。每个交换机有 k=48 个端口，因此这个机架总共有 48²=2304 个端口。

在这 k²=2304 个端口中，一半（k²/2=1152 个）用于连接机架内的交换机。我们是如何得出 k²/2 的？看看前面的一些概念图可能会有所帮助。k/2 个汇聚层交换机中的每个都有 k/2 条向下的链路，总共使用 (k/2)² 个端口。同样，k/2 个边缘层交换机中的每个都有 k/2 条向上的链路，总共使用 (k/2)² 个端口。这总共使用了 2×(k/2)²=k²/2 个端口。

请注意，汇聚层和边缘层交换机之间的链路是连接同一机架内的交换机。因此，每条链路需要两个端口（一个来自汇聚交换机，一个来自边缘交换机），这就是为什么我们将 (k/2)² 的值加倍（或者说，在汇聚层和边缘层都考虑了这个值）。

在 k²=2304 个端口中，另外四分之一（k²/4=576 个）用于连接交换机与同一 pod 内的主机。我们是如何得出这个数字的？记住，一个 pod 内有 (k/2)² 个主机，每个主机只连接到一个交换机。因此，我们需要 (k/2)²=k²/4 个交换机端口来连接主机。

最后，在 k²=2304 个端口中，剩下的四分之一（k²/4=576 个）用于将 pod 连接到核心层。我们是如何得出这个数字的？记住，有 (k/2)² 个核心交换机，每个核心交换机都有一条链路连接到每个 pod。换句话说，一个 pod 有一条单独的链路连接到 (k/2)² 个核心交换机中的每个。因此，我们需要 (k/2)²=k²/4 个交换机端口来连接到核心交换机。

总结一下：在 k² 个总端口中，一半用于互连同一层中的汇聚 / 边缘交换机（连接完全在中间的机架内进行）。另外四分之一用于将边缘交换机连接到 pod 内的主机（中间机架与周围 12 个有机架的主机之间的连接）。最后四分之一用于将汇聚交换机连接到核心层（中间机架与其他核心层机架之间的连接）。



![img](https://textbook.cs168.io/assets/datacenter/6-028-pods7.png)

## 现实世界中的拓扑结构



![img](https://textbook.cs168.io/assets/datacenter/6-029-irl-topology1.png)

在这个例子中（2008 年），任意两个终端主机之间有许多不同的路径。



![img](https://textbook.cs168.io/assets/datacenter/6-030-irl-topology2.png)

在这篇论文中（2015 年），研究了各种拓扑结构。

存在许多具体的变体（2009 年、2015 年），但它们都有一个共同的目标，即在任意两台服务器之间实现高带宽。

> （注：文档部分内容可能由 AI 生成）